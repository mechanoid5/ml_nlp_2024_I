{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac9bfcd8",
   "metadata": {},
   "source": [
    "**Статистическая языковая модель**\n",
    "\n",
    "Евгений Борисов <esborisov@sevsu.ru>\n",
    "\n",
    "подбираем наиболее вероятное продолжение цепочки слов (NLTK model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11c10ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8508779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url='http://lib.ru/NEWPROZA/LOBAS/taxisty.txt'\n",
    "# text = BeautifulSoup(requests.get(url).text).get_text()\n",
    "# with gzip.open('taxisty.txt.gz','wt') as f: f.write(text)\n",
    "\n",
    "# # with gzip.open('taxisty.txt.gz','rt') as f: text = f.read()\n",
    "\n",
    "# text = text[1030:-7261].strip() # выкидываем заголовок и хвост страницы \n",
    "# print(f'символов:{len(text)}\\n---------------\\n'%())\n",
    "# print(text[:343])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "babb7397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "символов:1279540\n",
      "---------------\n",
      "\n",
      "Приступая к описанию недавних и столь странных событий, происшедших в нашем, доселе ничем не отличавшемся городе, я принужден, по неумению моему, начать несколько издалека, а именно некоторыми биографическими подробностями о талантливом и многочтимом Степане Трофимовиче Верховенском. Пусть эти подробности послужат лишь введением к предлагаемой хронике, \n"
     ]
    }
   ],
   "source": [
    "url='http://az.lib.ru/d/dostoewskij_f_m/text_0080.shtml'\n",
    "text = BeautifulSoup(requests.get(url).text).get_text()\n",
    "with gzip.open('dostoewskij.txt.gz','wt') as f: f.write(text)\n",
    "\n",
    "# with gzip.open('dostoewskij.txt.gz','rt') as f: text = f.read()\n",
    "\n",
    "text = text[2876:-664184].strip() # выкидываем заголовок и хвост страницы \n",
    "print(f'символов:{len(text)}\\n---------------\\n'%())\n",
    "print(text[:355])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ca2b8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nltk version: 3.8.1\n"
     ]
    }
   ],
   "source": [
    "from nltk import __version__ as nltk_version\n",
    "print('nltk version:',nltk_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "765735ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86078745083c4168a9e93b8b587414cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14574 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "предложений: 14574\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Та',\n",
       "  'глядела',\n",
       "  'на',\n",
       "  'нее',\n",
       "  'ужасно',\n",
       "  'оробевшим',\n",
       "  ',',\n",
       "  'застыдившимся',\n",
       "  ',',\n",
       "  'но',\n",
       "  'почти',\n",
       "  'благоговейным',\n",
       "  'взглядом',\n",
       "  'и',\n",
       "  'вдруг',\n",
       "  'усмехнулась',\n",
       "  'с',\n",
       "  'тем',\n",
       "  'же',\n",
       "  'странным',\n",
       "  'хихиканьем',\n",
       "  '.']]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from random import sample\n",
    "\n",
    "from nltk.tokenize import sent_tokenize as nltk_sentence_split\n",
    "from nltk.tokenize import word_tokenize as nltk_tokenize_word\n",
    "\n",
    "sentences = [ \n",
    "    nltk_tokenize_word(s) # разбиваем предложения на слова\n",
    "    for s in tqdm(nltk_sentence_split(text)) # режем текст на отдельные предложения\n",
    "]\n",
    "\n",
    "print('предложений: %i\\n'%(len(sentences)))\n",
    "display( sample(sentences,1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e495cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sentences[:1024*7] # ограничиваем датасет для ускорения процеса "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e810ef5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 µs, sys: 2 µs, total: 12 µs\n",
      "Wall time: 14.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline \n",
    "\n",
    "ngram_len = 2\n",
    "\n",
    "# генерируем учебный датасет\n",
    "train, vocab = padded_everygram_pipeline(ngram_len, sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d08204f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20835"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# собираем модель\n",
    "\n",
    "# from nltk.lm import MLE as LangModel \n",
    "from nltk.lm import Laplace as LangModel\n",
    "\n",
    "model = LangModel(ngram_len) \n",
    "model.fit(train, vocab)\n",
    "\n",
    "display(len(model.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "309be2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Стоя на коленях , придавленный к земле , с вывернутыми на спину локтями , хитрый бродяга спокойно ожидал развязки , совершенно , ... ['когда', 'наконец', 'спросить']\n",
      "\n",
      "Он на месяц приедет , последнее имение продавать здесь ... ['ей', 'обещал', 'зайти']\n",
      "\n",
      "Но истина одна , а стало быть , только единый из народов и может иметь бога истинного , хотя бы остальные народы и ... ['прискакивая', ',', 'тогда']\n",
      "\n",
      "Поднялся смех , ропот ; толпа стеснилась , стали ругаться , дошло бы и до побоев , если ... ['противник', 'заранее', 'все']\n",
      "\n",
      "Заметно было , что mademoiselle Лебядкина белится и румянится и губы ... ['были', 'так', 'процветавшего']\n",
      "\n",
      "Я , знаете , устраиваю целый день увеселений , по подписке , в пользу бедных ... ['.', '</s>', 'Боже']\n",
      "\n",
      "А что если подымется крик и вместо величественной картины дойдет ... ['до', 'генерала', '.']\n",
      "\n",
      "- Если не к вам , то я пойду в сестры милосердия , в сиделки , ходить за больны ми , ... ['он', 'ни', 'Горацио']\n",
      "\n",
      "Еще раз повторяю : я и тогда считал его и теперь считаю ( когда уже всё кончено ) именно таким человеком , который , если бы получил удар в лицо или подобную равносильную обиду , то немедленно убил бы своего противника , ... ['и', 'понимаю', '!']\n",
      "\n",
      "Генерал устроил нарочно интимный вечерок , театр вынесли напоказ , все пять генеральских дочек с новобрачною Амалией , ее заводчик и многие барышни и барыни со своими немцами ... ['внимательно', ':', '``']\n",
      "\n",
      "Приступая к описанию недавних и столь странных событий , происшедших в нашем , доселе ничем не отличавшемся городе , я принужден , по неумению моему , начать несколько издалека , а именно некоторыми ... ['биографическими', 'подробностями', ',']\n",
      "\n",
      "Он молчал , смотрел на Шатова и бледнел как ... ['вы', 'по', 'тысяче']\n",
      "\n",
      "[ 60 ] Не более как через десять минут она явилась по обещанию , в ... ['записке', 'моей', 'стороне']\n",
      "\n",
      "Федька подхватывал на лету , кидался , бумажки сыпались в грязь , Федька ловил и прикрикивал : `` ... ['стук', 'вагона', ':']\n",
      "\n",
      "Лиза , которая млела за этими рассказами , чрезвычайно смешно передразнивала у себя ... ['безопасным', ',', 'а']\n",
      "\n",
      "Что сделали вы для меня в эти двадцать ... ['лет', 'тому', ',']\n",
      "\n",
      "Помните , потом в феврале , когда пронеслась весть , вы вдруг прибежали ко мне пере пуганный и стали требовать , чтоб я тотчас же дала вам удостоверение , в виде письма , что затеваемый журнал до вас совсем не касается , что молодые люди ходят ко мне , а не к вам , а что вы только ... ['перестала', 'смеяться', 'Nicolas']\n",
      "\n",
      "Все они , от неуменья вести дело , ужасно любят обвинять ... ['в', 'другом', ',']\n",
      "\n",
      "Но он иногда слишком много проигрывал в клубе , а просить у ... ['ней', 'множество', ',']\n",
      "\n",
      "Одним словом , это был день удивительно сошедшихся ... ['случайностей', '.', '</s>']\n",
      "\n",
      "То самое , в котором ты уведомлял , что она тебя эксплуатирует , завидуя твоему таланту , ну и там ... ['теперь', 'с', 'сего']\n",
      "\n",
      "- На прошлой неделе во вторник , нет , в среду , потому что уже ... ['выздоровел', 'и', 'время']\n",
      "\n",
      "Могу ли рассчитывать , что не откажете в средствах ... ['к', 'этой', 'несчастной']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# генерируем продолжения\n",
    "for sentence in sample(sentences,30): # выбираем рандомно 10 предложений\n",
    "    if len(sentence)<10: continue\n",
    "    # берём начало предложения\n",
    "    sentence_ = sentence[:-(len(sentence)//4)]\n",
    "    # генерируем возможные продолжения\n",
    "    result = model.generate(3, text_seed=sentence_) \n",
    "    print(  ' '.join(sentence_)  + ' ... ' + str( result ) + '\\n' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08863bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perplexity: 4018.948842449797\n"
     ]
    }
   ],
   "source": [
    "# from nltk.util import bigrams\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# оцениваем насколько хорошо модель предсказывает слова из датасета\n",
    "text_ngrams = [ ng for s in sentences for ng in ngrams(s,ngram_len) ]\n",
    "\n",
    "print( 'perplexity:', model.perplexity( text_ngrams ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29036d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Приступая', 'к'), ('к', 'описанию'), ('описанию', 'недавних')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display( text_ngrams[:3] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82488f46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
